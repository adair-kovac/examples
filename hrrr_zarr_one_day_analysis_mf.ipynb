{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8da0b2f-7cfa-4b2b-9102-cf855d0a9d55",
   "metadata": {},
   "source": [
    "This example shows how to get a day's worth of analysis files for a single variable and combine them using high-level APIs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d4c5883a-f81e-46a9-b57b-a5a134a45da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import s3fs\n",
    "import xarray as xr\n",
    "import metpy\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c0370a-1bc9-417b-be69-e6249e4ec2ac",
   "metadata": {},
   "source": [
    "We use xarray's open_mfdataset to load the data. There's a couple things missing from the metadata, so we use a metpy extension to add projection info and latitude/longitude. We also promote the \"time\" attribute to a coordinate so that combining the datasets for each hour will work later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "302b76bf-a853-4dd6-b6b8-7d32ae63fb1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(urls):\n",
    "    fs = s3fs.S3FileSystem(anon=True)\n",
    "    ds = xr.open_mfdataset([s3fs.S3Map(url, s3=fs) for url in urls], engine='zarr')\n",
    "    ds = ds.rename(projection_x_coordinate=\"x\", projection_y_coordinate=\"y\")\n",
    "    ds = ds.metpy.assign_crs(grid_mapping_name=\"lambert_conformal_conic\", longitude_of_central_meridian=-97.5,\n",
    "                                 latitude_of_projection_origin=38.5,\n",
    "                                 standard_parallel=38.5)\n",
    "    ds = ds.metpy.assign_latitude_longitude()\n",
    "    ds = ds.set_coords(\"time\")\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "256c668a-b9da-4a6e-98bb-5723c50ae0ac",
   "metadata": {},
   "source": [
    "The following function demonstrates how to format the urls to load the data, as well as how to combine the hours using xarray.concat. Note that because there's an extra level of nesting for the main data variable (level and variable name), we have to get both the zarr group url and the url for the nested subgroup. That's why we have to use open_mfdataset (\"mf\" means \"multifile\")––other zarr datasets likely won't have this quirk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fecad052-5bde-4b06-90e9-223bfe6e6371",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_combined_dataset(start_date, num_hours, level, param_short_name):\n",
    "    combined_ds = None\n",
    "    for i in range(num_hours):\n",
    "        time = start_date + datetime.timedelta(hours=i)\n",
    "        group_url = time.strftime(f\"s3://hrrrzarr/sfc/%Y%m%d/%Y%m%d_%Hz_anl.zarr/{level}/{param_short_name}\")\n",
    "        subgroup_url = group_url + f\"/{level}\"\n",
    "        partial_ds = load_dataset([group_url, subgroup_url])\n",
    "        if not combined_ds:\n",
    "            combined_ds = partial_ds\n",
    "        else:\n",
    "            combined_ds = xr.concat([combined_ds, partial_ds], dim=\"time\", combine_attrs=\"drop_conflicts\")\n",
    "    return combined_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ffc8f8-804e-44bc-be2f-b0004e725075",
   "metadata": {},
   "source": [
    "Just for demonstration purposes, we load up the data and calculate the standard deviation so we have something to plot across the geospatial domain. Note that this whole thing takes 2 minutes on my laptop, mostly spent on downloading the data. You'll need some performance optimizations or parallelization if you're doing a large analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a5209543-c14c-4391-8c1a-1aabdca06d58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 29 s, sys: 562 ms, total: 29.5 s\n",
      "Wall time: 1min 32s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ds = load_combined_dataset(datetime.datetime(2021, 4, 1), 24, \"1000mb\", \"TMP\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "411cddb0-2705-495d-aabf-335c8693ba6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 18.3 ms, sys: 16 ms, total: 34.3 ms\n",
      "Wall time: 34.2 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "std_dev = ds.TMP.std(dim=\"time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd4307d-cdba-4439-aa35-9b9f018f0835",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "ax.contourf(std_dev.longitude, std_dev.latitude, std_dev)\n",
    "ax.coastlines()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c15304-fb95-4c3b-b516-ffa7ea855c5d",
   "metadata": {},
   "source": [
    "**Troubleshoot:** In my Jupyter notebook setup, the pyproj package gives the following error when it tries looking up the projection info:\n",
    "\n",
    "```\n",
    "CRSError: Invalid datum string: urn:ogc:def:datum:EPSG::6326: (Internal Proj Error: proj_create: SQLite error on SELECT name, ellipsoid_auth_name, ellipsoid_code, prime_meridian_auth_name, prime_meridian_code, publication_date, frame_reference_epoch, deprecated FROM geodetic_datum WHERE auth_name = ? AND code = ?: no such column: publication_date)\n",
    "```\n",
    "\n",
    "I believe this is because I run Jupyter from a conda environment that's different than the kernel Jupyter is using. In any case, there's an easy fix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "32a25d6e-2645-405c-b7d2-621645e7191c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyproj\n",
    "#pyproj.datadir.set_data_dir(\"/Users/<me>/.conda/envs/<this notebook's kernel env>/share/proj\")\n",
    "pyproj.datadir.set_data_dir(\"/Users/adairkovac/.conda/envs/TetheredBalloon-7710/share/proj\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3de339b-eaf5-4f5c-94dd-da11eb8eac9f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TetheredBalloon-7710",
   "language": "python",
   "name": "tetheredballoon-7710"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
